{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Text_Explicit.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1UKf7odoO3f_zCibg-06oCx2gUr2o-vGA","authorship_tag":"ABX9TyN9Qo8hiK1Ncb96BmNxlToQ"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"0BF52w7D5r0A","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"53162508-f115-46d7-ee5a-71c6ae02cf3d","executionInfo":{"status":"ok","timestamp":1585950649543,"user_tz":-330,"elapsed":17348,"user":{"displayName":"Neel Shah","photoUrl":"https://lh3.googleusercontent.com/-uqDqdbKVmMs/AAAAAAAAAAI/AAAAAAAACP0/Fe19KJJ8Ji4/s64/photo.jpg","userId":"15671838399494525246"}}},"source":["%tensorflow_version 1.14\n","\n","#importing libraries\n","\n","from numpy import array\n","from numpy import asarray\n","from numpy import zeros\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Flatten, BatchNormalization\n","from keras.layers import Embedding, Dropout, Conv1D, MaxPooling1D\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","\n","df = pd.read_csv('drive/My Drive/The_Research/all_data_refined.csv')\n","a = df[df.columns[8: 14]]\n","# b,c,d,e,f,g = df['word_count',\t'average_word_count',\t'exclamation_count',\t'capital_count', 'question_count', 'negation_count'] #Change this accordingly\n","print(a)\n","#load the labels\n","\n","\n","type = df['type'] #Change this accordingly\n","labels = []\n","\n","for types in type:\n","  if types == 'real':\n","    labels.append(1)\n","  elif types == 'fake':\n","    labels.append(0)\n","\n","\n","\n","# define model\n","model = Sequential()\n","model.add(Dense(31, input_shape=(6, )))\n","model.add(Dense(128))\n","model.add(BatchNormalization())\n","model.add(Dropout(0.8))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(128, activation='relu'))\n","model.add(Dense(128))\n","model.add(BatchNormalization())\n","model.add(Dense(1, activation='sigmoid'))\n","\n","\n","# compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","\n","# summarize the model\n","print(\"____________________\")\n","print(model.summary())\n","print(\"____________________\")\n","\n","X_train, X_test, y_train, y_test = train_test_split(a, labels, test_size=0.33)\n","\n","# fit the model\n","model.fit(X_train, y_train, epochs=5, verbose=1)\n","\n","\n","# evaluate the model\n","print(\"____________________\")\n","loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n","print('Accuracy: %f' % (accuracy*100))\n","\n","count_true = 0\n","print(\"____________________\")\n","output = model.predict(a[:100])\n","for i in range(len(output)):\n","  if(output[i] > 0.5 and labels[i] == 1): count_true += 1\n","\n","\n","print(count_true)\n","\n","# save the model\n","model.save('textexplicit.h5')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["`%tensorflow_version` only switches the major version: 1.x or 2.x.\n","You set: `1.14`. This will be interpreted as: `1.x`.\n","\n","\n","TensorFlow is already loaded. Please restart the runtime to change versions.\n","       word_count  average_word_count  ...  question_count  negation_count\n","0            1082           12.729412  ...               2               0\n","1             344           10.117647  ...               0               0\n","2            1090           16.268657  ...               1               0\n","3            1302           13.151515  ...               0               0\n","4             518           14.000000  ...               0               0\n","...           ...                 ...  ...             ...             ...\n","20010         288           16.000000  ...               1               0\n","20011         369           17.571429  ...               0               0\n","20012         641           20.677419  ...               0               0\n","20013        1113           16.863636  ...               0               0\n","20014         821           14.155172  ...               1               8\n","\n","[20015 rows x 6 columns]\n","____________________\n","Model: \"sequential_18\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","dense_75 (Dense)             (None, 31)                217       \n","_________________________________________________________________\n","dense_76 (Dense)             (None, 128)               4096      \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 128)               512       \n","_________________________________________________________________\n","dropout_18 (Dropout)         (None, 128)               0         \n","_________________________________________________________________\n","dense_77 (Dense)             (None, 128)               16512     \n","_________________________________________________________________\n","dense_78 (Dense)             (None, 128)               16512     \n","_________________________________________________________________\n","dense_79 (Dense)             (None, 128)               16512     \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 128)               512       \n","_________________________________________________________________\n","dense_80 (Dense)             (None, 1)                 129       \n","=================================================================\n","Total params: 55,002\n","Trainable params: 54,490\n","Non-trainable params: 512\n","_________________________________________________________________\n","None\n","____________________\n","Epoch 1/5\n","13410/13410 [==============================] - 4s 263us/step - loss: 0.6454 - acc: 0.6456\n","Epoch 2/5\n","13410/13410 [==============================] - 1s 94us/step - loss: 0.6211 - acc: 0.6551\n","Epoch 3/5\n","13410/13410 [==============================] - 1s 97us/step - loss: 0.6161 - acc: 0.6635\n","Epoch 4/5\n","13410/13410 [==============================] - 1s 94us/step - loss: 0.6043 - acc: 0.6795\n","Epoch 5/5\n","13410/13410 [==============================] - 1s 97us/step - loss: 0.5919 - acc: 0.6943\n","____________________\n","6605/6605 [==============================] - 1s 148us/step\n","Accuracy: 73.565481\n","____________________\n","89\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fvQw8WFa-VcP","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}