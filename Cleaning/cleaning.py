# -*- coding: utf-8 -*-
"""cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19utCfP1S0b3KP4aaQ4bdMzAElZjgYset
"""

import pandas as pd
import re
import linguistics
import random
from datetime import date


def applyLinguistics(input_df):

  output_df = input_df
  text_input_df = input_df['text']
  title_input_df = input_df['title']

  cleanutil = []
  for i in range(len(title_input_df)):
    temp = clean(title_input_df[i])
    cleanutil.append(temp)
  output_df['title'] = cleanutil

  cleanutil = []
  for i in range(len(text_input_df)):
    temp = clean(text_input_df[i])
    cleanutil.append(temp)
    if cleanutil[-1] == "":
      cleanutil[-1] = "A"
      print("Empty: ", i)
  output_df['text'] = cleanutil

  wordcount = []
  for i in range(len(text_input_df)):
    temp = wordCount(text_input_df[i])
    wordcount.append(temp)
  output_df['word_count'] = wordcount

  averagewordcount = []
  for i in range(len(text_input_df)):
    temp = averageWordCount(text_input_df[i])
    averagewordcount.append(temp)
  output_df['average_word_count'] = averagewordcount

  exclamationcount = []
  for i in range(len(text_input_df)):
    temp = exclamationMarkCount(text_input_df[i])
    exclamationcount.append(temp)
  output_df['exclamation_count'] = exclamationcount

  capitalcount = []
  for i in range(len(text_input_df)):
    temp = capitalLetterCount(text_input_df[i])
    capitalcount.append(temp)
  output_df['capital_count'] = capitalcount

  questioncount = []
  for i in range(len(text_input_df)):
    temp = questionMarkCount(text_input_df[i])
    questioncount.append(temp)
  output_df['question_count'] = questioncount

  negationcount = []
  for i in range(len(text_input_df)):
    temp = negationCount(text_input_df[i])
    negationcount.append(temp)
  output_df['negation_count'] = negationcount

  fppcount = []
  for i in range(len(text_input_df)):
    temp = firstPersonPronounCount(text_input_df[i])
    fppcount.append(temp)
  output_df['fpp_count'] = fppcount

  return output_df



def processOnDf(df_in):
  df = df_in
  input_df = df.filter(['id', 'language', 'main_img_url', 'published', 'text', 'title', 'type', 'uuid'])
  output_df = applyLinguistics(input_df)
  output_df.to_csv('foo2.csv')
  return output_df

def processOnNewInput(id = 0, published = date.today(), text = "NA", title = 'notitle', language = 'english', uuid = 123456789, main_img_url = 'NULL'):
  df = pd.DataFrame()
  df = df.append({'id' : id, 'published' : str(published), 'text' : text, 'title' : title, 'language' : language, 'uuid' : uuid, 'main_img_url' : main_img_url}, ignore_index=True)
  df = applyLinguistics(df)
  return df

if __name__ == '__main__':
    
  #df = pd.read_csv('drive/My Drive/The_Research/all_data.csv', encoding='utf-8')
  #output_df = processOnDf(df)
  #output_df.to_csv('drive/My Drive/The_Research/all_data_refined.csv', encoding='utf-8')
  output_df = processOnNewInput(id = 1, published = date.today(),  text = "ab ", title = 'notitle', language = 'english', uuid = 123456790, main_img_url = 'https://www.google.com')



