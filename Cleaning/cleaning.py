# -*- coding: utf-8 -*-
"""Cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BdRu4o-YGYYpeviuouHXLk_kSLmpDmup
"""



import pandas as pd
import re
import Linguistics

def wordCount(content):
    wordCount,outside,inside = 0, 0, 1
    state = outside
    for i in content:
        if (i == ' ' or i == '\n' or i == '\t'):
            state = outside
        elif state == outside:
            state = inside
            wordCount += 1
    return wordCount

def averageWordCount(content):
    count = wordCount(content)
    sentences, outside, inside = 0, 0, 1
    state = outside
    for i in content:
        if (i == '.' or i == '!' or i == '?' or i == '...'):
            state = outside
        elif state == outside:
            state = inside
            sentences += 1
    if sentences == 0: return 0
    averageWords = count/sentences
    return averageWords

def characterCount(content, character):
    count = 0
    for i in content:
        if i == character:
            count += 1
    return count

def exclamationMarkCount(content):
    return characterCount(content, '!')

def capitalLetterCount(content):
    totalCount = 0
    alphabets = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    for i in alphabets:
        totalCount += characterCount(content, i)
    return totalCount
    
def questionMarkCount(content):
    return characterCount(content, '?')   
 

def wordify(content):
    return content.split(' ')

def wordwiseCount(content, finderWords):
    count = 0
    wordList = wordify(content)
    for i in wordList:
        if i in finderWords:
            count += 1
    return count

def negationCount(content):
    negations = ["do not", "don't", "does not", "doesn't", "am not", "are not", "aren't", "is not", "isn't", "did not", "didn't", "have not", "haven't", "had not", "hadn't", "should not", "shouldn't", "would not", "wouldn't", "will not", "won't"]
    return wordwiseCount(content.lower(), negations)

def firstPersonPronounCount(content):
    pronounsList = ["I", "me", "we", "us", "my", "mine", "our", "ours"]
    return wordwiseCount(content.lower(), pronounsList)
    

def displayLinguistics(content):
    wc = wordCount(content)
    print("Word count: " + str(wc))
    awc = averageWordCount(content)
    print("Average word count: " + str(awc))
    ec = exclamationMarkCount(content)
    print("Exclamation marks present: " + str(ec))
    cc = capitalLetterCount(content)
    print("Capital letters present: " + str(cc))
    qc = questionMarkCount(content)
    print("Question marks present: " + str(qc))
    nc = negationCount(content)
    print("Negations used: " + str(nc))
    fc = firstPersonPronounCount(content)
    print("First person pronouns present: " + str(fc))


def clean(text):
    cleaned_txt = re.sub('<[A-Za-z0-9+]*>', "", text)
    return cleaned_txt




def applyLinguistics(input_df):

  text_input_df = input_df['text']
  output_df = input_df
  title_input_df = input_df['title']

  cleanutil = []
  for i in range(len(title_input_df)):
    temp = clean(title_input_df[i])
    cleanutil.append(temp)
  output_df['title'] = cleanutil

  cleanutil = []
  for i in range(len(text_input_df)):
    temp = clean(text_input_df[i])
    cleanutil.append(temp)
    if cleanutil[-1] == "":
      cleanutil[-1] = "A"
      print("Empty: ", i)
  output_df['text'] = cleanutil


  wordcount = []
  for i in range(len(text_input_df)):
    temp = wordCount(text_input_df[i])
    wordcount.append(temp)
  output_df['word_count'] = wordcount

  averagewordcount = []
  for i in range(len(text_input_df)):
    temp = averageWordCount(text_input_df[i])
    averagewordcount.append(temp)
  output_df['average_word_count'] = averagewordcount

  exclamationcount = []
  for i in range(len(text_input_df)):
    temp = exclamationMarkCount(text_input_df[i])
    exclamationcount.append(temp)
  output_df['exclamation_count'] = exclamationcount

  capitalcount = []
  for i in range(len(text_input_df)):
    temp = capitalLetterCount(text_input_df[i])
    capitalcount.append(temp)
  output_df['capital_count'] = capitalcount

  questioncount = []
  for i in range(len(text_input_df)):
    temp = questionMarkCount(text_input_df[i])
    questioncount.append(temp)
  output_df['question_count'] = questioncount


  negationcount = []
  for i in range(len(text_input_df)):
    temp = negationCount(text_input_df[i])
    negationcount.append(temp)
  output_df['negation_count'] = negationcount

  fppcount = []
  for i in range(len(text_input_df)):
    temp = firstPersonPronounCount(text_input_df[i])
    fppcount.append(temp)
  output_df['fpp_count'] = fppcount

  return output_df





df = pd.read_csv('drive/My Drive/The_Research/all_data.csv', encoding='utf-8')
df.head()
input_df = df.filter(['id', 'language', 'main_img_url', 'published', 'text', 'title', 'type', 'uuid'])
# 7, 8, 10, 13, 18, 20, 21, 22
#input_df = input_df[:1000]
output_df = applyLinguistics(input_df)
output_df.head()
output_df.to_csv(r'drive/My Drive/The_Research/all_data_refined.csv', index = False)

test_df = pd.read_csv('drive/My Drive/The_Research/all_data_refined.csv', encoding='utf-8')
test_df.shape

test_df[: 5653]

