# -*- coding: utf-8 -*-
"""cleaning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19utCfP1S0b3KP4aaQ4bdMzAElZjgYset
"""

import pandas as pd
import re
import linguistics
import random
from datetime import date


def wordCount(content):
    wordCount,outside,inside = 0, 0, 1
    state = outside
    for i in content:
        if (i == ' ' or i == '\n' or i == '\t'):
            state = outside
        elif state == outside:
            state = inside
            wordCount += 1
    return wordCount

def averageWordCount(content):
    count = wordCount(content)
    sentences, outside, inside = 0, 0, 1
    state = outside
    for i in content:
        if (i == '.' or i == '!' or i == '?' or i == '...'):
            state = outside
        elif state == outside:
            state = inside
            sentences += 1
    averageWords = count/sentences
    return averageWords

def characterCount(content, character):
    count = 0
    for i in content:
        if i == character:
            count += 1
    return count

def exclamationMarkCount(content):
    return characterCount(content, '!')

def capitalLetterCount(content):
    totalCount = 0
    alphabets = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
    for i in alphabets:
        totalCount += characterCount(content, i)
    return totalCount
    
def questionMarkCount(content):
    return characterCount(content, '?')   
 
def capitalWordCount(content):
    capitalCount = 0
    regex = '\s+[A-Z][A-Z]+\s|^[A-Z][A-Z]+.|\s+[A-Z][A-Z]+.|^[A-Z][A-Z]+:|\s+[A-Z][A-Z]+:|^[A-Z][A-Z]+,|\s+[A-Z][A-Z]+,'
    words = re.findall(regex, content)
    capitalCount = len(words)
    return capitalCount

def wordify(content):
    return content.split(' ')

def wordwiseCount(content, finderWords):
    count = 0
    wordList = wordify(content)
    for i in wordList:
        if i in finderWords:
            count += 1
    return count

def negationCount(content):
    negations = ["do not", "don't", "does not", "doesn't", "am not", "are not", "aren't", "is not", "isn't", "did not", "didn't", "have not", "haven't", "had not", "hadn't", "should not", "shouldn't", "would not", "wouldn't", "will not", "won't"]
    return wordwiseCount(content.lower(), negations)

def firstPersonPronounCount(content):
    pronounsList = ["I", "me", "we", "us", "my", "mine", "our", "ours"]
    return wordwiseCount(content.lower(), pronounsList)


def clean(text):
    cleaned_txt = re.sub('<[A-Za-z0-9+]*>', "", text)
    return cleaned_txt

def displayLinguistics(content):
    wc = wordCount(content)
    print("Word count: " + str(wc))
    awc = averageWordCount(content)
    print("Average word count: " + str(awc))
    ec = exclamationMarkCount(content)
    print("Exclamation marks present: " + str(ec))
    cc = capitalLetterCount(content)
    print("Capital letters present: " + str(cc))
    qc = questionMarkCount(content)
    print("Question marks present: " + str(qc))
    nc = negationCount(content)
    print("Negations used: " + str(nc))
    fc = firstPersonPronounCount(content)
    print("First person pronouns present: " + str(fc))
    cwc = capitalWordCount(content)
    print("Capital Words present: " + str(cwc))



def applyLinguistics(input_df):

  output_df = input_df
  text_input_df = input_df['text']
  title_input_df = input_df['title']

  cleanutil = []
  for i in range(len(title_input_df)):
    temp = clean(title_input_df[i])
    cleanutil.append(temp)
  output_df['title'] = cleanutil

  cleanutil = []
  for i in range(len(text_input_df)):
    temp = clean(text_input_df[i])
    cleanutil.append(temp)
    if cleanutil[-1] == "":
      cleanutil[-1] = "A"
      print("Empty: ", i)
  output_df['text'] = cleanutil

  wordcount = []
  for i in range(len(text_input_df)):
    temp = wordCount(text_input_df[i])
    wordcount.append(temp)
  output_df['word_count'] = wordcount

  averagewordcount = []
  for i in range(len(text_input_df)):
    temp = averageWordCount(text_input_df[i])
    averagewordcount.append(temp)
  output_df['average_word_count'] = averagewordcount

  exclamationcount = []
  for i in range(len(text_input_df)):
    temp = exclamationMarkCount(text_input_df[i])
    exclamationcount.append(temp)
  output_df['exclamation_count'] = exclamationcount

  capitalcount = []
  for i in range(len(text_input_df)):
    temp = capitalLetterCount(text_input_df[i])
    capitalcount.append(temp)
  output_df['capital_count'] = capitalcount

  questioncount = []
  for i in range(len(text_input_df)):
    temp = questionMarkCount(text_input_df[i])
    questioncount.append(temp)
  output_df['question_count'] = questioncount

  negationcount = []
  for i in range(len(text_input_df)):
    temp = negationCount(text_input_df[i])
    negationcount.append(temp)
  output_df['negation_count'] = negationcount

  fppcount = []
  for i in range(len(text_input_df)):
    temp = firstPersonPronounCount(text_input_df[i])
    fppcount.append(temp)
  output_df['fpp_count'] = fppcount

  return output_df



def processOnDf(df_in):
  df = df_in
  input_df = df.filter(['id', 'language', 'main_img_url', 'published', 'text', 'title', 'type', 'uuid'])
  output_df = applyLinguistics(input_df)
  output_df.to_csv('foo2.csv')
  return output_df

def processOnNewInput(id = 0, published = date.today(), text = "NA", title = 'notitle', language = 'english', uuid = 123456789, main_img_url = 'NULL'):
  df = pd.DataFrame()
  df = df.append({'id' : id, 'language' : language, 'main_img_url' : main_img_url, 'published' : str(published), 'text' : text, 'title' : title , 'type' : 'real', 'uuid' : uuid, }, ignore_index=True)
  df = applyLinguistics(df)
  return df

if __name__ == '__main__':
    
  #df = pd.read_csv('drive/My Drive/The_Research/all_data.csv', encoding='utf-8')
  #output_df = processOnDf(df)
  #output_df.to_csv('drive/My Drive/The_Research/all_data_refined.csv', encoding='utf-8')
  output_df = processOnNewInput(id = 1, published = date.today(),  text = "ab ", title = 'notitle', language = 'english', uuid = 123456790, main_img_url = 'https://www.google.com')



